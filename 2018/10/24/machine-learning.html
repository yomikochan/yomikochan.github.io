<h3 id="前言">前言</h3>

<p>机器学习可以做许多有趣的事情，每个技术方向都有入门例子，但实际上只是照着入门例子抄，然后跑一遍可能对入门并没有帮助。于是我就个人入门经验，用自己的例子来做一个入门指导吧。</p>

<p>虽然是入门，但这里并不会指导进行环境搭建，所以，在看这篇文章之前，请先准备好机器学习的环境。</p>

<h3 id="你将会了解到的">你将会了解到的</h3>

<ol>
  <li>什么是数据集</li>
  <li>如何训练模型</li>
  <li>模型的复用</li>
</ol>

<h3 id="什么是数据集">什么是数据集</h3>

<p>我个人觉得入门不太合适一上来就教如何数据处理，特征工程，应该先对做机器学习过程有一个大体了解，然后再深入细节，学习更多细节方面的东西。</p>

<p>首先我的例子是这样的：</p>

<p>预测方程 $ a_n = a_{n - 2} + a_{n - 4} + 1 $ 的第 $ n $ 项的值。（不要求答案完全正确，误差在 1e7 左右）</p>

<p>正常来说，这种问题不会用机器学习来做，明明可以写个递归跑，干嘛非要机器学习，误差还很大？嘛…你就当计算非常大的项 $ n $ 时，跑递归计算很慢，觉得不爽，只想知道值大概范围即可。</p>

<p>那么你可以继续往下看。。。</p>

<p>我们首先要有数据集让机器能学习，如何弄到数据集呢，呃，监督学习似乎都可以用表格来存储数据并作为数据集，对于上面这个问题，显然是回归任务，它是属于监督学习的。</p>

<p>而数据集一般也分为训练集和测试集，顾名思义，训练集用于训练，测试集用来测试训练好的模型的效果如何。</p>

<p>下面Python代码用来生成问题的训练集（python很慢）：</p>

<div class="language-py highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="kn">import</span> <span class="nn">pandas</span> <span class="k">as</span> <span class="n">pd</span>


<span class="k">def</span> <span class="nf">recursive</span><span class="p">(</span><span class="n">x</span><span class="p">):</span>
    <span class="k">if</span> <span class="n">x</span> <span class="o">&lt;=</span> <span class="mi">2</span><span class="p">:</span>
        <span class="k">return</span> <span class="mi">1</span>
    <span class="k">else</span><span class="p">:</span>
        <span class="k">return</span> <span class="n">recursive</span><span class="p">(</span><span class="n">x</span> <span class="o">-</span> <span class="mi">2</span><span class="p">)</span> <span class="o">+</span> <span class="n">recursive</span><span class="p">(</span><span class="n">x</span> <span class="o">-</span> <span class="mi">4</span><span class="p">)</span> <span class="o">+</span> <span class="mi">1</span>


<span class="n">x</span> <span class="o">=</span> <span class="p">[]</span>
<span class="n">y</span> <span class="o">=</span> <span class="p">[]</span>
<span class="n">c</span> <span class="o">=</span> <span class="mi">1</span>
<span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="mi">66</span><span class="p">):</span>
    <span class="n">x</span><span class="p">.</span><span class="n">append</span><span class="p">(</span><span class="n">i</span><span class="p">)</span>
    <span class="k">if</span> <span class="n">i</span> <span class="o">%</span> <span class="mi">2</span> <span class="o">!=</span> <span class="mi">0</span><span class="p">:</span>
        <span class="n">c</span> <span class="o">=</span> <span class="n">recursive</span><span class="p">(</span><span class="n">i</span><span class="p">)</span>
    <span class="n">y</span><span class="p">.</span><span class="n">append</span><span class="p">(</span><span class="n">c</span><span class="p">)</span>

<span class="n">save</span> <span class="o">=</span> <span class="n">pd</span><span class="p">.</span><span class="n">DataFrame</span><span class="p">({</span><span class="s">'data'</span><span class="p">:</span> <span class="n">x</span><span class="p">,</span> <span class="s">'result'</span><span class="p">:</span> <span class="n">y</span><span class="p">})</span>
<span class="n">save</span><span class="p">.</span><span class="n">to_csv</span><span class="p">(</span><span class="s">'train.csv'</span><span class="p">,</span> <span class="n">index</span><span class="o">=</span><span class="bp">False</span><span class="p">)</span>
</code></pre></div></div>

<p>这里我选择0~65用来训练，66~86用来测试。你可以用两个文件中分别保存训练集和测试集，也可以把所有数据放在同一个文件，然后训练时只取一部分。我用了两个文件。</p>

<p><strong>一般比赛时，主办方会提供数据集，所以，大家其实不太重视如何生成数据集，而更多的关注的是数据清洗等问题。</strong></p>

<h3 id="如何训练模型">如何训练模型</h3>

<p>前面也提到这是一个回归任务，那么至少要知道应该用 sklearn 提供的 linear_model 来做这个问题。</p>

<p>问题很单一，所以我们不需要数据预处理。。。</p>

<p>不过为什么用回归任务的线性模块算法，看看数据分布关系，就明白了：</p>

<div class="language-py highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="kn">import</span> <span class="nn">pandas</span> <span class="k">as</span> <span class="n">pd</span>
<span class="kn">import</span> <span class="nn">seaborn</span> <span class="k">as</span> <span class="n">sns</span>

<span class="n">train</span> <span class="o">=</span> <span class="n">pd</span><span class="p">.</span><span class="n">read_csv</span><span class="p">(</span><span class="s">'train.csv'</span><span class="p">)</span>
<span class="n">sns</span><span class="p">.</span><span class="n">lmplot</span><span class="p">(</span><span class="n">x</span><span class="o">=</span><span class="s">'data'</span><span class="p">,</span> <span class="n">y</span><span class="o">=</span><span class="s">'result'</span><span class="p">,</span> <span class="n">data</span><span class="o">=</span><span class="n">train</span><span class="p">)</span>
<span class="n">plt</span><span class="p">.</span><span class="n">show</span><span class="p">()</span>
</code></pre></div></div>

<p><img src="/img/Figure_1.png" alt="img1" /></p>

<p>然后很简单的拟合，并保存模型：</p>

<pre><code class="language-Python">import pandas as pd
import numpy as np
import seaborn as sns
import matplotlib.pyplot as plt
from sklearn.metrics import mean_squared_error, r2_score
from sklearn.linear_model import Lasso, RidgeCV, ElasticNet, BayesianRidge, LinearRegression, LogisticRegression
from sklearn.model_selection import train_test_split
from sklearn.externals import joblib
from sklearn.preprocessing import PolynomialFeatures


train = pd.read_csv('train.csv')
train_X, train_y = train.iloc[:, :-1].values, train['result']

poly_reg = PolynomialFeatures(degree=9) # 2333
X = poly_reg.fit_transform(train_X)
clf = LinearRegression()
print(clf.fit(X, train_y)) # 拟合

# c = clf.coef_
# print('参数：', c)

plt.scatter(train_X, train_y)
plt.plot(X, clf.predict(X))
plt.xlabel('data')
plt.ylabel('result')
plt.show()

joblib.dump(clf, 'save_model.m') # 拟合后，随意取个名字保存即可
</code></pre>

<p>把大多数回归模型可以用的算法都试过以后，发现还是非线性回归转线性回归最合适，误差也小一些。然而评分看着很高，却并没有什么用（笑）</p>

<h3 id="模型的复用">模型的复用</h3>

<p>上面保存了训练好的模型，我们随时可以用它来做事:</p>

<div class="language-py highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="kn">import</span> <span class="nn">pandas</span> <span class="k">as</span> <span class="n">pd</span>
<span class="kn">import</span> <span class="nn">numpy</span> <span class="k">as</span> <span class="n">np</span>
<span class="kn">import</span> <span class="nn">seaborn</span> <span class="k">as</span> <span class="n">sns</span>
<span class="kn">import</span> <span class="nn">matplotlib.pyplot</span> <span class="k">as</span> <span class="n">plt</span>
<span class="kn">from</span> <span class="nn">sklearn.metrics</span> <span class="kn">import</span> <span class="n">mean_squared_error</span><span class="p">,</span> <span class="n">r2_score</span>
<span class="kn">from</span> <span class="nn">sklearn.linear_model</span> <span class="kn">import</span> <span class="n">Lasso</span><span class="p">,</span> <span class="n">RidgeCV</span><span class="p">,</span> <span class="n">ElasticNet</span><span class="p">,</span> <span class="n">BayesianRidge</span><span class="p">,</span> <span class="n">LinearRegression</span><span class="p">,</span> <span class="n">LogisticRegression</span>
<span class="kn">from</span> <span class="nn">sklearn.externals</span> <span class="kn">import</span> <span class="n">joblib</span>
<span class="kn">from</span> <span class="nn">sklearn.preprocessing</span> <span class="kn">import</span> <span class="n">PolynomialFeatures</span>

<span class="n">test</span> <span class="o">=</span> <span class="n">pd</span><span class="p">.</span><span class="n">read_csv</span><span class="p">(</span><span class="s">'test.csv'</span><span class="p">)</span>
<span class="n">test_X</span><span class="p">,</span> <span class="n">test_y</span> <span class="o">=</span> <span class="n">test</span><span class="p">.</span><span class="n">iloc</span><span class="p">[:,</span> <span class="p">:</span><span class="o">-</span><span class="mi">1</span><span class="p">].</span><span class="n">values</span><span class="p">,</span> <span class="n">test</span><span class="p">[</span><span class="s">'result'</span><span class="p">]</span>

<span class="n">clf</span> <span class="o">=</span> <span class="n">joblib</span><span class="p">.</span><span class="n">load</span><span class="p">(</span><span class="s">'save_model.m'</span><span class="p">)</span>
<span class="n">poly_reg</span> <span class="o">=</span> <span class="n">PolynomialFeatures</span><span class="p">(</span><span class="n">degree</span><span class="o">=</span><span class="mi">9</span><span class="p">)</span>
<span class="n">X</span> <span class="o">=</span> <span class="n">poly_reg</span><span class="p">.</span><span class="n">fit_transform</span><span class="p">(</span><span class="n">test_X</span><span class="p">)</span>
<span class="n">pred</span> <span class="o">=</span> <span class="n">clf</span><span class="p">.</span><span class="n">predict</span><span class="p">(</span><span class="n">X</span><span class="p">)</span> <span class="c1"># 预测
</span><span class="k">print</span><span class="p">(</span><span class="n">pred</span><span class="p">)</span>
<span class="k">print</span><span class="p">(</span><span class="s">'均方误差：%.2f'</span> <span class="o">%</span> <span class="n">mean_squared_error</span><span class="p">(</span><span class="n">y_true</span><span class="o">=</span><span class="n">test_y</span><span class="p">,</span> <span class="n">y_pred</span><span class="o">=</span><span class="n">pred</span><span class="p">))</span>
<span class="k">print</span><span class="p">(</span><span class="s">'评分：%.2f'</span> <span class="o">%</span> <span class="n">r2_score</span><span class="p">(</span><span class="n">y_true</span><span class="o">=</span><span class="n">test_y</span><span class="p">,</span> <span class="n">y_pred</span><span class="o">=</span><span class="n">pred</span><span class="p">))</span>
</code></pre></div></div>
